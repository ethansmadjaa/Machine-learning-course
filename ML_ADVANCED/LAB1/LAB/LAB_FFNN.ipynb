{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feed Forward Neural Network",
   "id": "532c1da9c3f0ba0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1: Load Data\n",
    "We start by downloading and loading the dataset `data_ffnn.txt`. The file consists of three columns: `x1`, `x2`, and `y`. This is a multi-class problem.\n"
   ],
   "id": "d36785448091dee9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:05.495662Z",
     "start_time": "2025-01-21T17:29:05.490941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the data\n",
    "file_path = \"data_ffnn.txt\"  # Ensure this file is in your working directory\n",
    "data = pd.read_csv(file_path, sep='\\s+', header=0, names=['x1', 'x2', 'y'])\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n"
   ],
   "id": "f884ddd3240ea39f",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Plot the Data\n",
    "Visualize the data in 2D, coloring each point according to its class.\n"
   ],
   "id": "7c304abc0592b573"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:05.599980Z",
     "start_time": "2025-01-21T17:29:05.496520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in data['y'].unique():\n",
    "    subset = data[data['y'] == label]\n",
    "    plt.scatter(subset['x1'], subset['x2'], label=f'Class {label}')\n",
    "    \n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('Data Visualization 2D')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "347e59d745c0077d",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Forward Propagation\n",
    "We implement forward propagation for a feedforward neural network with three layers. The hidden layer will have `K` neurons.\n"
   ],
   "id": "1f7e8289d03f0e34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:05.603353Z",
     "start_time": "2025-01-21T17:29:05.600507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_propagation(X, V, W):\n",
    "    \"\"\"\n",
    "    Perform forward propagation through the neural network.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like\n",
    "        Input data of shape (n_samples, n_features)\n",
    "    V : array-like\n",
    "        Weight matrix for hidden layer\n",
    "    W : array-like\n",
    "        Weight matrix for output layer\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing:\n",
    "        - X_bar: Input data with bias term\n",
    "        - X_bar_bar: Input to hidden layer\n",
    "        - F: Hidden layer activation\n",
    "        - F_bar: Hidden layer output with bias\n",
    "        - F_bar_bar: Input to output layer\n",
    "        - G: Network output\n",
    "        - E: Sum of Squared Error\n",
    "    \"\"\"\n",
    "    # Add bias term to input\n",
    "    X_bar = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "    \n",
    "    # Hidden layer\n",
    "    X_bar_bar = np.dot(X_bar, V)\n",
    "    F = 1 / (1 + np.exp(-X_bar_bar))  # sigmoid activation\n",
    "    F_bar = np.hstack((np.ones((F.shape[0], 1)), F))\n",
    "    F_bar_bar = np.dot(F_bar, W)\n",
    "    \n",
    "    # Output layer\n",
    "    G = 1 / (1 + np.exp(-F_bar_bar))  # Sigmoid activation\n",
    "    \n",
    "    # Store all intermediate values\n",
    "    results = {\n",
    "        'X_bar': X_bar,\n",
    "        'X_bar_bar': X_bar_bar,\n",
    "        'F': F,\n",
    "        'F_bar': F_bar,\n",
    "        'F_bar_bar': F_bar_bar,\n",
    "        'G': G,\n",
    "\n",
    "    }\n",
    "    \n",
    "    return results\n"
   ],
   "id": "98f40caa791db48",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:05.607913Z",
     "start_time": "2025-01-21T17:29:05.604512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define network parameters\n",
    "N = 2  # input features\n",
    "K = 4  # hidden neurons\n",
    "J = len(data['y'].unique())  # output classes\n",
    "\n",
    "# Initialize weights\n",
    "V = np.random.randn(N + 1, K)\n",
    "W = np.random.randn(K + 1, J)\n",
    "\n",
    "# Prepare input data\n",
    "X = data[['x1', 'x2']].values\n",
    "\n",
    "# Perform forward propagation\n",
    "results = forward_propagation(X, V, W)\n",
    "\n",
    "# Create one-hot encoded target\n",
    "y_true_onehot = np.eye(J)[data['y'].astype(int)]\n",
    "\n",
    "X_bar = results['X_bar']\n",
    "F_bar = results['F_bar']\n",
    "F = results['F']\n",
    "G = results['G']\n",
    "\n",
    "# Calculate error\n",
    "E = 0.5 * np.sum((results['G'] - y_true_onehot) ** 2)\n",
    "print(f\"Error: {E:.4f}\")\n",
    "\n",
    "y_pred = np.argmax(results['G'], axis=1)\n",
    "print(\"\\nFirst few predictions vs actual:\")\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {y_pred[i]}, Actual: {data['y'].iloc[i]}\")"
   ],
   "id": "c33c993427ea03e7",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 4: back propagation\n",
   "id": "331b61e98390e4dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:05.610545Z",
     "start_time": "2025-01-21T17:29:05.608472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the learning rates\n",
    "alpha_1, alpha_2 = 10**-3, 10**-3\n",
    "\n",
    "# Define the number of iterations\n",
    "iterations = 0\n",
    "\n",
    "# Define a threshold\n",
    "threshold = 10**-4\n",
    "\n",
    "# Define an error array\n",
    "errors = [10**-5,E]\n",
    "\n"
   ],
   "id": "a8607ef9090e490f",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:05.613326Z",
     "start_time": "2025-01-21T17:29:05.611152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backpropagation(V_BP, W_BP, X_bar_BP, F_BP, F_bar_BP, G_BP, y_one_hot_BP, alpha_1_BP, alpha_2_BP):\n",
    "\n",
    "    # Step 1: Calculate output layer error\n",
    "    delta_G = G_BP * (1 - G_BP) * (G_BP - y_one_hot_BP)\n",
    "    \n",
    "    # Step 2: Calculate hidden layer error\n",
    "    \n",
    "    # First, get the term coming from the next layer\n",
    "    dGxWT = np.dot(delta_G, W_BP.T)\n",
    "    \n",
    "    # Calculate δf while excluding the bias thats why we do * dGxWT[:, 1:]\n",
    "    delta_F = F_BP * (1 - F_BP) * dGxWT[:, 1:]\n",
    "    \n",
    "    # Step 3: Calculate gradients\n",
    "    \n",
    "    # For output layer weights (W)\n",
    "    dE_dW = np.dot(F_bar_BP.T, delta_G)\n",
    "    \n",
    "    # For hidden layer weights (V)\n",
    "    dE_dV = np.dot(X_bar_BP.T, delta_F)\n",
    "       \n",
    "    # Step 4: update weights\n",
    "    \n",
    "    # Update W and V using gradient descent\n",
    "    W_new = W_BP - alpha_1_BP * dE_dW\n",
    "    V_new = V_BP - alpha_2_BP * dE_dV\n",
    "    \n",
    "    return W_new, V_new\n"
   ],
   "id": "7945b563b269f225",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:06.306981Z",
     "start_time": "2025-01-21T17:29:05.614009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "while abs(errors[-1] - errors[-2]) > threshold or  iterations < 10000:\n",
    "    \n",
    "    iterations += 1\n",
    "    \n",
    "    #backpropagation and weight updates\n",
    "    W, V = backpropagation(V, W, X_bar, F, F_bar, G, y_true_onehot, alpha_1, alpha_2)\n",
    "    \n",
    "    # Forward propagation\n",
    "    results = forward_propagation(X, V, W)\n",
    "    F = results['F']\n",
    "    F_bar = results['F_bar']\n",
    "    G = results['G']\n",
    "    \n",
    "    # calculate error\n",
    "    E = 0.5 * np.sum((G - y_true_onehot) ** 2)    \n",
    "    errors.append(E)\n",
    "    \n",
    "    if iterations % 1000 == 0:\n",
    "        print(f\"Iteration {iterations}, Error: {E}\")\n",
    "        \n",
    "#final results\n",
    "print(\"\\nFinal Error:\", errors[-1])\n",
    "print(\"Number of iterations:\", len(errors))\n",
    "    \n"
   ],
   "id": "cfa6e044e6c79e44",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 5: Plotting the errors",
   "id": "890f7b9ceb7937ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:06.353141Z",
     "start_time": "2025-01-21T17:29:06.307601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tracer la réduction de l'erreur\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(errors, label=\"Erreur SSE\")\n",
    "plt.xlabel(\"Itérations\")\n",
    "plt.ylabel(\"Erreur (SSE)\")\n",
    "plt.title(\"Réduction de l'erreur au fil des itérations\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "97d9ef8d37145825",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 6: Optimal parameters",
   "id": "81a7844e5f32662c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:06.355998Z",
     "start_time": "2025-01-21T17:29:06.353639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def display_weights(V, W):\n",
    "    \"\"\"\n",
    "    Affiche simplement les matrices de poids V et W\n",
    "    \"\"\"\n",
    "    print(\"\\nMatrice V (couche cachée):\")\n",
    "    print(V)\n",
    "    print(\"\\nMatrice W (couche de sortie):\")\n",
    "    print(W)\n",
    "\n",
    "    print(\"\\nTailles des matrices:\")\n",
    "    print(f\"V: {V.shape} - entrée vers couche cachée\")\n",
    "    print(f\"W: {W.shape} - couche cachée vers sortie\")\n",
    "\n",
    "# Afficher les poids\n",
    "display_weights(V, W)"
   ],
   "id": "c47e5fea9ee310a2",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 7: plotting training outputs values vs Predicted values",
   "id": "a1c9b9ec1e2ca565"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:06.464674Z",
     "start_time": "2025-01-21T17:29:06.357732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get predictions for training data\n",
    "results = forward_propagation(X, V, W)\n",
    "predicted_outputs = results['G']\n",
    "predicted_classes = np.argmax(predicted_outputs, axis=1)\n",
    "actual_classes = data['y'].values\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted_classes == actual_classes)\n",
    "print(f\"Classification Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot predicted vs actual classes\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot actual classes\n",
    "plt.subplot(121)\n",
    "for label in np.unique(actual_classes):\n",
    "    mask = actual_classes == label\n",
    "    plt.scatter(X[mask, 0], X[mask, 1], label=f'Class {label}')\n",
    "plt.title('Actual Classes')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "\n",
    "# Plot predicted classes\n",
    "plt.subplot(122)\n",
    "for label in np.unique(predicted_classes):\n",
    "    mask = predicted_classes == label\n",
    "    plt.scatter(X[mask, 0], X[mask, 1], label=f'Class {label}')\n",
    "plt.title('Predicted Classes')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\nDetailed Comparison (first 10 samples):\")\n",
    "print(\"Sample\\tActual\\tPredicted\")\n",
    "print(\"-\" * 30)\n",
    "for i in range(10):\n",
    "    print(f\"{i}\\t{actual_classes[i]}\\t{predicted_classes[i]}\")"
   ],
   "id": "203e66d0103a0b89",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 8: Testing the model with values",
   "id": "53ebee8d2965d4e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:06.530490Z",
     "start_time": "2025-01-21T17:29:06.465202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test data points\n",
    "X_test = np.array([\n",
    "    [0, 0],    # Test point 1\n",
    "    [2, 2],    # Test point 2\n",
    "    [4, 4],    # Test point 3\n",
    "    [4.5, 1.5] # Test point 4\n",
    "])\n",
    "\n",
    "# Perform forward propagation on test data\n",
    "test_output = forward_propagation(X_test, V, W)\n",
    "\n",
    "# Get predicted classes\n",
    "predicted_classes = np.argmax(test_output['G'], axis=1)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training data\n",
    "for label in np.unique(data['y']):\n",
    "    mask = data['y'] == label\n",
    "    plt.scatter(data[mask]['x1'], data[mask]['x2'], \n",
    "               alpha=0.5, label=f'Training Class {label}')\n",
    "\n",
    "# Plot test points\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], \n",
    "           color='red', marker='*', s=200, \n",
    "           label='Test Points')\n",
    "\n",
    "# Add annotations for test points\n",
    "for i, (x, y) in enumerate(X_test):\n",
    "    plt.annotate(f'T{i+1}\\nClass {predicted_classes[i]}', \n",
    "                (x, y), xytext=(10, 10), \n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.title('Test Points and Their Predicted Classes')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate prediction confidence\n",
    "confidences = np.max(test_output['G'], axis=1)\n",
    "print(\"\\nPrediction Confidences:\")\n",
    "print(\"-\" * 40)\n",
    "for i, conf in enumerate(confidences):\n",
    "    print(f\"Test Point {i+1}: {conf:.3f}\")"
   ],
   "id": "774af9dd051f417c",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 9: Plot classification results",
   "id": "24c19259e2f3af3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:06.654879Z",
     "start_time": "2025-01-21T17:29:06.531132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create subplots for comparison\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 1. Original Data Plot (Given classes)\n",
    "plt.subplot(121)\n",
    "for label in np.unique(data['y']):\n",
    "    mask = data['y'] == label\n",
    "    plt.scatter(data[mask]['x1'], data[mask]['x2'], \n",
    "               label=f'Class {label}')\n",
    "\n",
    "plt.title('Original Data with Given Classes')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 2. Model Predictions (Training + Test points)\n",
    "plt.subplot(122)\n",
    "\n",
    "# Get predictions for training data\n",
    "train_output = forward_propagation(X, V, W)\n",
    "train_pred = np.argmax(train_output['G'], axis=1)\n",
    "\n",
    "# Plot training predictions\n",
    "for label in np.unique(train_pred):\n",
    "    mask = train_pred == label\n",
    "    plt.scatter(X[mask, 0], X[mask, 1], \n",
    "               label=f'Predicted Class {label}')\n",
    "\n",
    "# Get and plot test predictions\n",
    "test_output = forward_propagation(X_test, V, W)\n",
    "test_pred = np.argmax(test_output['G'], axis=1)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], \n",
    "           color='red', marker='*', s=200,\n",
    "           label='Test Points')\n",
    "\n",
    "# Label test points\n",
    "for i, (x, y) in enumerate(X_test):\n",
    "    plt.annotate(f'T{i+1}\\nClass {test_pred[i]}', \n",
    "                (x, y), xytext=(10, 5),\n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.title('Model Predictions\\n(Training + Test Points)')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print test point predictions\n",
    "print(\"\\nTest Point Classifications:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Point (x1, x2)      | Predicted Class\")\n",
    "print(\"-\" * 50)\n",
    "for i, (point, pred) in enumerate(zip(X_test, test_pred)):\n",
    "    print(f\"T{i+1}: ({point[0]:.1f}, {point[1]:.1f})  | Class {pred}\")"
   ],
   "id": "6f006bea42fee5ca",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:29:06.656590Z",
     "start_time": "2025-01-21T17:29:06.655410Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "22a16718c57d9412",
   "execution_count": 36,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
