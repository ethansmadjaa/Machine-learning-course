{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the classification metrics from scratch\n",
    "\n",
    "To this exercise you will need to implement the precision, recall, and f1-measure without using scikit-learn or any other library that already implements such metrics.\n",
    "\n",
    "Your algorithm should take as input the predictions made on the test set (y_pred) and the actual class values of such set (y_test).\n",
    "\n",
    "You will need to find at least the TP, FP, and FN to compute the three metrics.\n",
    "\n",
    "You can use this part of code to help your implementation or you can define your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.98\n",
      "Recall: 0.93\n",
      "F1-Score: 2.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "   \n",
    "    #True positive\n",
    "    TP = 0 \n",
    "    #False positive\n",
    "    FP = 0\n",
    "    for i in range(len(y_true)) :\n",
    "    # if both y_pred and y_true are positive then it's a true positive so we increment TP\n",
    "      if y_pred[i] == 1 and y_true[i] == 1 :\n",
    "       TP += 1\n",
    "\n",
    "    # if the predicted label is true  and the true label is false it's a false positive so we increment FP\n",
    "      elif y_pred[i] == 1 and y_true[i] == 0 :\n",
    "        FP +=1\n",
    "    \n",
    "    return TP/(TP+FP)\n",
    "    \n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    TP = 0 \n",
    "    #False Negative \n",
    "    FN = 0\n",
    "    for i in range(len(y_true)) :\n",
    "    # if both y_pred and y_true are positive then it's a true positive so we increment TP\n",
    "     if y_pred[i] == 1 and y_true[i] == 1 :\n",
    "      TP += 1\n",
    "    # if the predicted label is false  and the true label is true it's a false negative so we increment FP\n",
    "     elif y_pred[i] == 0 and y_true[i] == 1 :\n",
    "      FN +=1\n",
    "\n",
    "    #avoiding the division by zero \n",
    "    if TP+FN==0 :\n",
    "      return 0\n",
    "    return TP/(TP + FN)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_test, y_pred)\n",
    "    r = recall(y_test, y_pred)\n",
    "\n",
    "    if p + r == 0 :\n",
    "       return 0\n",
    "    return 2 * (p * r)/p + r\n",
    "\n",
    "# Fit a model and make predictions\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall and F1-score\n",
    "p = precision(y_test, y_pred)\n",
    "r = recall(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision: {:.2f}\".format(p))\n",
    "print(\"Recall: {:.2f}\".format(r))\n",
    "print(\"F1-Score: {:.2f}\".format(f1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
