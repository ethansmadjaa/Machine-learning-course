{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the value of a used car is one of the main everyday challenges in the automotive business. We believe that the sales price of a car is not only based on the value of the product itself, but is also heavily influenced by things like market trends, current availability, and politics.\n",
    "With this challenge, we hope to raise some interest in this exciting topic and also gain some insight into what the main factors are that drive the value of a used car.\n",
    "\n",
    "The data provided consists of almost 5000 real BMW cars that were sold via a b2b auction in 2018. The price shown in the table is the highest bid that was reached during the auction.\n",
    "\n",
    "We have already done some data cleanup and filtered out cars with engine damage etc. However, there may still be minor damages like scratches, but we do not have more information about that.\n",
    "\n",
    "We have also extracted 8 criteria based on the equipment of cars that we think might have a good impact on the value of a used car. These criteria have been labeled feature1 to feature8 and are shown in the data below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:39.068138Z",
     "start_time": "2024-11-07T16:07:38.952451Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Reading data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:39.080203Z",
     "start_time": "2024-11-07T16:07:39.069582Z"
    }
   },
   "source": "df = pd.read_csv(\"./data/bmw_pricing_challenge.csv\")",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:39.088461Z",
     "start_time": "2024-11-07T16:07:39.081388Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:39.091519Z",
     "start_time": "2024-11-07T16:07:39.089225Z"
    }
   },
   "source": [
    "df.shape"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:39.098041Z",
     "start_time": "2024-11-07T16:07:39.091982Z"
    }
   },
   "source": [
    "df.describe()"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Missing Values\n",
    "Check if the dataset contains any missing values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:39.101759Z",
     "start_time": "2024-11-07T16:07:39.098600Z"
    }
   },
   "source": "print(df.isnull().sum())",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There are no missing values"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Distribution of the target variable\n",
    "Plot the probabilistic distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:39.252620Z",
     "start_time": "2024-11-07T16:07:39.102335Z"
    }
   },
   "source": [
    "# Plot the probabilistic distribution of the target variable 'price'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['price'], kde=True, bins=30)\n",
    "plt.title('Distribution of Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Distribution of numerical variables\n",
    "Plot the probabilistic distribution of the numerical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:39.688652Z",
     "start_time": "2024-11-07T16:07:39.254272Z"
    }
   },
   "source": [
    "numerical_features = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "# Plot the probabilistic distribution of the numerical features\n",
    "plt.figure(figsize=(15, 12))\n",
    "for idx, feature in enumerate(numerical_features):\n",
    "    plt.subplot(3, 3, idx + 1)\n",
    "    sns.histplot(df[feature], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Histogram of categorical variables\n",
    "Plot the histogram of the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.337572Z",
     "start_time": "2024-11-07T16:07:39.690952Z"
    }
   },
   "source": [
    "# Selecting only categorical features from the dataset\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "# Adjusting the histogram plots for categorical features for better readability\n",
    "\n",
    "# Filtering out 'registration_date' as it doesn't suit categorical plotting in this form\n",
    "filtered_categorical_features = categorical_features.drop('registration_date')\n",
    "\n",
    "# Plot the histogram of the categorical features with better visualization\n",
    "plt.figure(figsize=(20, 25))\n",
    "for idx, feature in enumerate(filtered_categorical_features):\n",
    "    plt.subplot(4, 2, idx + 1)\n",
    "    df[feature].value_counts().plot(kind='bar', color='skyblue', alpha=0.7)\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting\n",
    "\n",
    "Split the dataset into 2 training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.340564Z",
     "start_time": "2024-11-07T16:07:40.338394Z"
    }
   },
   "source": [
    "def split_data(df, ratio=0.8):\n",
    "    # we just need to shuffle the data before proceeding, and reset the index\n",
    "    shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # we're getting the ratio\n",
    "    index = int(df.shape[0] * ratio)\n",
    "\n",
    "    # so here we're splitting the data into test and train using our index variable\n",
    "    train_df = shuffled_df.iloc[:index]\n",
    "    test_df = shuffled_df.iloc[index:]\n",
    "\n",
    "    # and we're getting the data used to predict and dropping it from X_train and X_test\n",
    "    y_train = train_df['price']\n",
    "    y_test = test_df['price']\n",
    "    X_train = train_df.drop(columns=['price', 'price^2'], axis=1)\n",
    "    X_test = test_df.drop(columns=['price', 'price^2'], axis=1)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.345626Z",
     "start_time": "2024-11-07T16:07:40.341160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Just printing the head of the dataframe before shuffling\n",
    "df.head()"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    ## 4. Feature Engineering"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Removing non-predictive features\n",
    "\n",
    "Remove any unnecessary feature.\n",
    "\n",
    "We can categorize unnecessary features as an id, a string that's not really necessary, in our case the maker since they're all the same"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.350098Z",
     "start_time": "2024-11-07T16:07:40.346175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop('maker_key', axis=1, inplace=True)\n",
    "df.drop('model_key', axis=1, inplace=True)\n",
    "df.drop('registration_date', axis=1, inplace=True)\n",
    "df.drop('sold_at', axis=1, inplace=True)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Creating new features\n",
    "\n",
    "Creating polynomial features for numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.353053Z",
     "start_time": "2024-11-07T16:07:40.350628Z"
    }
   },
   "source": [
    "numerical_columns = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "degree = 2\n",
    "\n",
    "# Create polynomial features up to the specified degree\n",
    "for col in numerical_columns:\n",
    "    for d in range(2, degree + 1):\n",
    "        new_col_name = f\"{col}^\" + str(d)\n",
    "        df[new_col_name] = df[col] ** d\n"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.358254Z",
     "start_time": "2024-11-07T16:07:40.353630Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Scaling numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.362260Z",
     "start_time": "2024-11-07T16:07:40.359159Z"
    }
   },
   "source": [
    "# Select numerical columns as we added some\n",
    "numerical_columns = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "# Calculate mean and standard deviation for scaling\n",
    "for col in numerical_columns:\n",
    "    mean = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    df[col] = (df[col] - mean) / std"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.367578Z",
     "start_time": "2024-11-07T16:07:40.362931Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Categorical variables encoding\n",
    "\n",
    "Convert categorical columns into numerical columns using label encoding or one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.371432Z",
     "start_time": "2024-11-07T16:07:40.368059Z"
    }
   },
   "source": [
    "categorical_columns = df.select_dtypes(include=['object', 'datetime']).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    unique_values = df[col].unique()\n",
    "    encoding_map = {value: label for label, value in enumerate(unique_values)}\n",
    "    df[col] = df[col].map(encoding_map)"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Converting boolean columns\n",
    "\n",
    "Convert categorical columns into numerical columns using label encoding or one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.379764Z",
     "start_time": "2024-11-07T16:07:40.371979Z"
    }
   },
   "source": [
    "boolean_columns = df.select_dtypes(include=['bool']).columns\n",
    "\n",
    "for col in boolean_columns:\n",
    "    df[col] = df[col].apply(lambda x: 1 if x == True else 0)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.6 Splitting the data\n",
    "\n",
    "we're going to use the previously created split_data function"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.383271Z",
     "start_time": "2024-11-07T16:07:40.380282Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, y_train, X_test, y_test = split_data(df, ratio=0.8)",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linear Regression\n",
    "\n",
    "### 5.1 Fit a linear regression model on the training set. Evaluate the model on the testing set. Use the $R^2$ as an evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.401151Z",
     "start_time": "2024-11-07T16:07:40.383773Z"
    }
   },
   "source": [
    "linearRegression = LinearRegression()\n",
    "\n",
    "# fit the model to the training data\n",
    "linearRegression.fit(X_train, y_train)\n",
    "\n",
    "# use the model to predict on the test set\n",
    "y_pred_Linear_regression = linearRegression.predict(X_test)\n",
    "\n",
    "# Here I'm simply getting the R2 score of this model\n",
    "linearRegression_R2 = r2_score(y_test, y_pred_Linear_regression)\n",
    "\n",
    "# evaluate the model using r2_score\n",
    "print(\"R squared score of the LinearRegression model: \", linearRegression_R2)\n",
    "\n",
    "# Here I'm simply getting the MSE score of this model\n",
    "linearRegression_MSE = mean_squared_error(y_test, y_pred_Linear_regression)\n",
    "\n",
    "# Evaluate the model using MSE score\n",
    "print(\"MSE of lasso model: \", linearRegression_MSE)"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5.2 Plot feature importance/weight."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.671887Z",
     "start_time": "2024-11-07T16:07:40.402727Z"
    }
   },
   "source": [
    "linearRegression_coefs = pd.DataFrame(\n",
    "    linearRegression.coef_, columns=[\"Coefficients\"], index=X_train.columns\n",
    ")\n",
    "linearRegression_coefs.plot(kind=\"barh\", figsize=(9, 7))\n",
    "plt.title(\"Linear regression\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ridge\n",
    "### 6.1 Fit a ridge regression model on the training set. Use cross-validation in order to tune the regularization parameter of the ridge model. Evaluate the model on the testing set. Use the $R^2$ as an evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:40.952216Z",
     "start_time": "2024-11-07T16:07:40.674206Z"
    }
   },
   "source": [
    "# define a list of alpha\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# create and fit the RidgeCV regression model\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Getting the best alpha found by the LassoCv model\n",
    "best_alpha_ridge = ridge_cv.alpha_\n",
    "\n",
    "# Print the best alpha value that we got from fitting ridge_cv\n",
    "print(f\"Best alpha value found by RidgeCV: {best_alpha_ridge}\")\n",
    "\n",
    "# use the model to predict on the test set\n",
    "y_pred_ridge = ridge_cv.predict(X_test)\n",
    "\n",
    "# Here I'm simply getting the R2 score of this model\n",
    "ridgeCV_R2 = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "# evaluate the model using r2_score\n",
    "print(\"R squared score of ridge model: \", ridgeCV_R2)\n",
    "\n",
    "# Here I'm simply getting the MSE score of this model\n",
    "ridgeCV_MSE = mean_squared_error(y_test, y_pred_ridge)\n",
    "\n",
    "# Evaluate the model using MSE score\n",
    "print(\"MSE of lasso model: \", ridgeCV_MSE)"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6.2 Plot feature importance/weight."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:41.153474Z",
     "start_time": "2024-11-07T16:07:40.953434Z"
    }
   },
   "source": [
    "ridge_coefs = pd.DataFrame(\n",
    "    ridge_cv.coef_, columns=[\"Coefficients\"], index=X_train.columns\n",
    ")\n",
    "ridge_coefs.plot(kind=\"barh\", figsize=(9, 7))\n",
    "plt.title(\"Linear regression\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lasso\n",
    "### 7.1 Fit a lasso regression model on the training set. Use cross-validation in order to tune the regularization parameter of the ridge model. Evaluate the model on the testing set. Use the $R^2$ as an evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:41.217530Z",
     "start_time": "2024-11-07T16:07:41.154889Z"
    }
   },
   "source": [
    "# define a list of alpha\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# create and fit the LassoCV regression model\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# Getting the best alpha found by the LassoCv model\n",
    "best_alpha_lasso = lasso_cv.alpha_\n",
    "\n",
    "# Print the best alpha value that we got from fitting lasso_cv\n",
    "print(f\"Best alpha value found by LassoCV: {best_alpha_lasso}\")\n",
    "\n",
    "# use the model to predict on the test set\n",
    "y_pred_lasso = lasso_cv.predict(X_test)\n",
    "\n",
    "# Here I'm simply getting the R2 score of this model\n",
    "lassoCV_R2 = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# evaluate the model using r2 score\n",
    "print(\"R squared score of lasso model: \", lassoCV_R2)\n",
    "\n",
    "# Here I'm simply getting the MSE score of this model\n",
    "lassoCV_MSE = mean_squared_error(y_test, y_pred_lasso)\n",
    "\n",
    "# Evaluate the model using MSE score\n",
    "print(\"MSE of lasso model: \", lassoCV_MSE)"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 7.2 Plot feature importance/weight."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:41.365121Z",
     "start_time": "2024-11-07T16:07:41.219342Z"
    }
   },
   "source": [
    "lasso_coefs = pd.DataFrame(\n",
    "    lasso_cv.coef_, columns=[\"Coefficients\"], index=X_train.columns\n",
    ")\n",
    "lasso_coefs.plot(kind=\"barh\", figsize=(9, 7))\n",
    "plt.title(\"Lasso Linear regression\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)\n",
    "plt.show()"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Model comparison\n",
    "\n",
    "   ### 8.1 $R^2$ comparison\n",
    "\n",
    "The goal here is to compare the $R^2$ metric to see which of the model has performed the best, and in the case of RidgeCV and LassoCV, compare which alpha value the cross validation chose to get the best out of the parameters"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:41.372829Z",
     "start_time": "2024-11-07T16:07:41.366572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "R2_scores = {'LinearRegression': linearRegression_R2,\n",
    "             'RidgeCV': ridgeCV_R2,\n",
    "             'LassoCV': lassoCV_R2}\n",
    "\n",
    "print(\"R squared score of the LinearRegression model: \", R2_scores['LinearRegression'])\n",
    "\n",
    "ridge_R2 = r2_score(y_test, y_pred_ridge)\n",
    "print(\"R squared score of RidgeCV model: \", R2_scores['RidgeCV'])\n",
    "\n",
    "lasso_R2 = r2_score(y_test, y_pred_lasso)\n",
    "print(\"R squared score of LassoCV model: \", R2_scores['LassoCV'])"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We're plotting $R^2$ scores of the different models so that we can compare the small yet significant variations between the models"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:41.517312Z",
     "start_time": "2024-11-07T16:07:41.408211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=list(R2_scores.keys()), y=list(R2_scores.values()), palette='Reds')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('R² Score')\n",
    "plt.ylim(0.70, 0.715)\n",
    "plt.title('R² Scores of Different Models')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In conclusion, we evaluated multiple linear regression models, including Linear Regression, Ridge Regression, and Lasso Regression. By using cross-validation and hyperparameter tuning, we were able to identify the optimal model parameters and compare their performance based on R² scores. All three models performed similarly, but slight variations in the R² scores highlight the benefits of regularization. Ridge and Lasso helped reduce overfitting while maintaining comparable predictive power. Feature importance analysis further provided insights into which features were most impactful in predicting car prices, helping us better understand the relationships in the data."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 8.2 MSE comparison\n",
    "Here by stocking the alphas in a dictionary we're going to be able to compare them and see the difference"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:41.612560Z",
     "start_time": "2024-11-07T16:07:41.519083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_MSE = {'LinearRegression': linearRegression_MSE,\n",
    "          'RidgeCV': ridgeCV_MSE,\n",
    "          'LassoCV': lassoCV_MSE}\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=list(model_MSE.keys()), y=list(model_MSE.values()), palette='Reds')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('MSE Value ')\n",
    "plt.ylim(0.285, 0.29)\n",
    "plt.title('Best MSE Values of each Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here the $MSE$ of the RidgeCV model is a just a bit yet significantly higher than LassoCV's and LinearRegression's $MSE$. Compared to the $R^2$, RidgeCV was lower than the two others, this can be explained by RidgeCV applying stronger regularization, thereby reducing model complexity at the cost of slightly lower predictive accuracy."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 8.3 Alpha's comparison\n",
    "\n",
    "Here by stocking the alphas in a dictionary we're going to be able to compare them and see the difference"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:41.858012Z",
     "start_time": "2024-11-07T16:07:41.614325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_alphas = {'RidgeCV': best_alpha_ridge,\n",
    "                'LassoCV': best_alpha_lasso}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=list(model_alphas.keys()), y=list(model_alphas.values()), palette='Reds')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Alpha Value (Log Scale)')\n",
    "plt.title('Best Alpha Values of RidgeCV and LassoCV Models')\n",
    "plt.show()"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that even if they have pretty close $MSE$ and $R^2$, they have very differents alpha values ("
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 8.4 Features comparison\n",
    "After comparing alphas and $R^2$ scores we can understand for each model which features has been important or not. First let's remind us what are the three plots we found for each model"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:07:42.112264Z",
     "start_time": "2024-11-07T16:07:41.858897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_coefs = {'LinearRegression': linearRegression_coefs,\n",
    "               'LassoCV': lasso_coefs,\n",
    "               'RidgeCV': ridge_coefs}\n",
    "plt.figure(figsize=(8, 8))\n",
    "for name, coefs in model_coefs.items():\n",
    "    coefs.plot(kind=\"barh\", figsize=(9, 7))\n",
    "    plt.title(\"{name}'s feature importance\".format(name=name))\n",
    "    plt.axvline(x=0, color=\".5\")\n",
    "    plt.subplots_adjust(left=0.3)\n",
    "    plt.show()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It's clear that the mileage has a lot to do with the car's price, but when we're comparing the models we can see that some feature's importance may vary from one model to another. In RidgeCV's model the car's engine power is way more important than in the two other ones, and even when comparing LassoCV and LinearRegression this feature's importance respectively lowers. and this can be explained by the different levels of regularization. RidgeCV applies stronger L2 regularization, which reduces the influence of less important features but may also limit the impact of more critical ones like engine power, resulting in a shift in feature importance compared to LassoCV and LinearRegression."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This project successfully predicted the auction price of used BMW cars using various features like vehicle attributes and equipment criteria. Through exploratory data analysis, significant patterns and influential features were identified. The modeling phase utilized linear, Ridge, and Lasso regressions, with Ridge providing the best results. These findings provide a valuable basis for pricing strategies in the used car market, highlighting data-driven insights for better decision-making."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
